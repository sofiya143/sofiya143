import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load the dataset
def load_data():
    # Load the dataset (make sure the file is in the same directory or provide full path)
    df = pd.read_csv('traffic_accidents.csv')
    return df

# Step 2: Data Preprocessing
def preprocess_data(df):
    # Checking for missing values
    print("Checking for missing values:")
    print(df.isnull().sum())
    
    # Fill missing values (simple strategy: replace with column mean or mode)
    df['weather'] = df['weather'].fillna(df['weather'].mode()[0])
    df['traffic_volume'] = df['traffic_volume'].fillna(df['traffic_volume'].mean())
    
    # Convert 'time' into the hour of the day (time feature)
    df['hour'] = pd.to_datetime(df['time'], format='%H:%M').dt.hour
    
    # Convert 'date' into day of the week (weekday feature)
    df['day_of_week'] = pd.to_datetime(df['date']).dt.weekday
    
    # Encode categorical features like 'weather'
    df['weather'] = df['weather'].astype('category').cat.codes
    
    # Check the changes
    print("\nData after preprocessing:")
    print(df.head())
    
    return df

# Step 3: Feature Selection and Train/Test Split
def prepare_data(df):
    # Define features (X) and target variable (y)
    X = df[['weather', 'traffic_volume', 'hour', 'day_of_week']]  # Features
    y = df['accident_severity']  # Target variable (severity)

    # Split the data into training and testing sets (80% train, 20% test)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    return X_train, X_test, y_train, y_test

# Step 4: Train the Machine Learning Model
def train_model(X_train, y_train):
    # Initialize the RandomForestClassifier
    model = RandomForestClassifier(n_estimators=100, random_state=42)

    # Train the model
    model.fit(X_train, y_train)
    
    return model

# Step 5: Model Evaluation
def evaluate_model(model, X_test, y_test):
    # Make predictions on the test set
    y_pred = model.predict(X_test)

    # Show evaluation metrics
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    print("\nConfusion Matrix:")
    print(cm)

    # Visualize the Confusion Matrix
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Minor", "Major"], yticklabels=["Minor", "Major"])
    plt.title("Confusion Matrix")
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

# Step 6: Feature Importance
def plot_feature_importance(model, X):
    # Get feature importance
    importances = model.feature_importances_

    # Create a bar plot of feature importance
    features = X.columns
    indices = np.argsort(importances)[::-1]

    plt.figure(figsize=(10, 6))
    plt.title('Feature Importance')
    plt.barh(range(X.shape[1]), importances[indices], align="center")
    plt.yticks(range(X.shape[1]), [features[i] for i in indices])
    plt.xlabel('Relative Importance')
    plt.show()

# Step 7: Make Predictions on New Data
def predict_new_data(model):
    # Example: Predict accident severity for a new data point
    new_data = pd.DataFrame({
        'weather': [2],  # Let's say 2 represents 'Clear'
        'traffic_volume': [50],  # Number of vehicles
        'hour': [15],  # 3 PM
        'day_of_week': [3]  # Thursday
    })

    # Predict accident severity
    prediction = model.predict(new_data)
    print(f"\nPredicted accident severity: {prediction[0]}")  # 0: Minor, 1: Major

# Main Function
def main():
    # Step 1: Load and preprocess the data
    df = load_data()

    # Step 2: Preprocess the data (handle missing values, create features)
    df = preprocess_data(df)

    # Step 3: Prepare data (split into train/test sets)
    X_train, X_test, y_train, y_test = prepare_data(df)

    # Step 4: Train the model
    model = train_model(X_train, y_train)

    # Step 5: Evaluate the model
    evaluate_model(model, X_test, y_test)

    # Step 6: Plot feature importance
    plot_feature_importance(model, X_train)

    # Step 7: Make a prediction for new data
    predict_new_data(model)

if __name__ == "__main__":
    main()
    
    
